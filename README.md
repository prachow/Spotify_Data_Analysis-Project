# ðŸŽ§ Spotify Data Analysis Project (AWS Data Pipeline)

This project implements a complete data pipeline to analyze Spotify music data using AWS services: S3, Glue, Athena, and QuickSight.

---

## ðŸ“Œ Pipeline Overview

1. **Upload CSV files** (albums, artists, tracks) to S3 using Python
2. **Catalog datasets** using AWS Glue Crawler
3. **Join datasets** via Glue ETL job (PySpark)
4. **Query with Athena**
5. **Visualize in QuickSight**

---

## ðŸ“ Project Structure
Spotify-Data-Analysis-Project/
â”œâ”€â”€ dataset/                  # Local .csv files
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ join_spotify_data.py  # Glue ETL PySpark script
â”œâ”€â”€ upload_to_s3.py           # Uploads data to S3
â”œâ”€â”€ deploy_glue.py            # Creates Glue DB, Crawler, and Job
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## âš™ï¸ Requirements

- Python 3.7+
- AWS CLI (`aws configure`)
- S3 bucket (e.g. `spotifydataa`)
- IAM role with access to S3, Glue, Athena

Install dependencies:
```bash
pip install boto3 tqdm

1. Upload CSVs to S3
        python upload_to_s3.py

2. Deploy Glue Crawler & Job
        python deploy_glue.py

3.Query with Athena
        In the Athena console:
	â€¢	Select database: spotify_db
	â€¢	Query the joined dataset from processed/ location

4. Visualize in QuickSight
	â€¢	Connect to Athena
	â€¢	Select spotify_db > joined_data
	â€¢	Create charts and dashboards

ðŸ§  Built With
	â€¢	AWS S3 â€“ Storage
	â€¢	AWS Glue â€“ Crawler & ETL
	â€¢	AWS Athena â€“ Serverless SQL
	â€¢	AWS QuickSight â€“ Visualization
	â€¢	Python (boto3, tqdm)
